name=test-couchbase-sink
connector.class=com.couchbase.connect.kafka.CouchbaseSinkConnector
tasks.max=2
topics=couchbase-sink-example

# Couchbase Server location
connection.cluster_address=127.0.0.1
connection.timeout.ms=2000

# connection.ssl.enabled=true
# connection.ssl.keystore.location=/tmp/keystore
# connection.ssl.keystore.password=secret

connection.bucket=receiver
connection.username=receiver
connection.password=secret

# couchbase.document.id=/id
# couchbase.remove.document.id=true

# The following *.converter properties are appropriate when reading from
# a topic whose messages have String (or null) keys and raw JSON values,
# without schemas. These are the correct settings to use with the code in
# the examples/json-producer directory.
key.converter=org.apache.kafka.connect.storage.StringConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
value.converter.schemas.enable=false

# If you're using Confluent, the Couchbase Sink Connector can also read
# messages published in the Avro format. Replace the above *.converter
# properties with the following (modifying the schema registry URL if needed):
#   key.converter=io.confluent.connect.avro.AvroConverter
#   key.converter.schema.registry.url=http://localhost:8081
#   value.converter=io.confluent.connect.avro.AvroConverter
#   value.converter.schema.registry.url=http://localhost:8081
